{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5np0f8d6n5ti"
   },
   "outputs": [],
   "source": [
    "# Импорт необходимых модулей \n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Настройки для визуализации\n",
    "# Если используется темная тема - лучше текст сделать белым\n",
    "TEXT_COLOR = 'black'\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (15, 10)\n",
    "matplotlib.rcParams['text.color'] = 'black'\n",
    "matplotlib.rcParams['font.size'] = 14\n",
    "matplotlib.rcParams['axes.labelcolor'] = TEXT_COLOR\n",
    "matplotlib.rcParams['xtick.color'] = TEXT_COLOR\n",
    "matplotlib.rcParams['ytick.color'] = TEXT_COLOR\n",
    "\n",
    "# Зафиксируем состояние случайных чисел\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4dJttl0xebt"
   },
   "source": [
    "# Случайные леса на Титанике\n",
    "\n",
    "Ахой, дамы и господа! Мы уже знакомились с игрушечными задачками для решения, когда данных было не так много и в них не было особо проблем: ни пропусков, ни строковых значений - все уже готово для модели. В этот раз мы возьмем данные посложнее и посмотрим, как работать с наиболее распространенными случаями предобработки!\n",
    "\n",
    "В этот раз мы идем в плавание и планируем научиться предсказывать выживет ли человек или нет! В этом нам поможет набор данных с Kaggle - [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic). Вы можете скачать данные прямо с сайта, ну а мы для примеров возьмем уже скачанный файл данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "executionInfo": {
     "elapsed": 2427,
     "status": "ok",
     "timestamp": 1601746084101,
     "user": {
      "displayName": "Алексей Девяткин",
      "photoUrl": "",
      "userId": "11945040185410340858"
     },
     "user_tz": -180
    },
    "id": "zeAnrA_b5JuW",
    "outputId": "11027af1-4aec-4834-a1fc-a653aafd857b"
   },
   "outputs": [],
   "source": [
    "URL = 'https://raw.githubusercontent.com/KaiL4eK/ml_edu/master/datasets/Titanic_train.csv'\n",
    "src_df = pd.read_csv(URL)\n",
    "src_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KWDH8wwu5U2x"
   },
   "source": [
    "На официальном сайте предоставлена информация по данным, сделаем краткое обобщение:\n",
    "- `Survived` - (Целевая переменная) булевая переменная - выжил или нет;\n",
    "- `PassengerId` - уникальный идентификатор пассажира; \n",
    "- `Pclass` - класс обслуживания;\n",
    "- `Name` - имя пассажира;\n",
    "- `Sex` - пол пассажира;\n",
    "- `Age` - возраст пассажира (вещественное - возраст менее 1; х.5 - призблизительная оценка);\n",
    "- `SibSp` - количество родственников на борту (братья, сестры, мужья, жены);\n",
    "- `Parch` - количество родственников на борту (матери, отцы, дочери, сыновья);\n",
    "- `Ticket` - номер билета;\n",
    "- `Fare` - плата за проезд;\n",
    "- `Cabin` - номер кабины;\n",
    "- `Embarked` - порт посадки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "executionInfo": {
     "elapsed": 2404,
     "status": "ok",
     "timestamp": 1601746084102,
     "user": {
      "displayName": "Алексей Девяткин",
      "photoUrl": "",
      "userId": "11945040185410340858"
     },
     "user_tz": -180
    },
    "id": "Y0H4LHTU5UkB",
    "outputId": "c1cd91c6-c129-461c-9840-21ce81e72ea8"
   },
   "outputs": [],
   "source": [
    "print(f'Shape of data: {src_df.shape}')\n",
    "print(src_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "executionInfo": {
     "elapsed": 2381,
     "status": "ok",
     "timestamp": 1601746084103,
     "user": {
      "displayName": "Алексей Девяткин",
      "photoUrl": "",
      "userId": "11945040185410340858"
     },
     "user_tz": -180
    },
    "id": "5mU02duL5gx-",
    "outputId": "f8a69697-74f2-4b49-ab5a-0a202ee13f31"
   },
   "outputs": [],
   "source": [
    "src_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Myhjy7s25e3X"
   },
   "source": [
    "Видим 891 запись, 12 колонок: 11 колонок данных и целевая переменная. Как видно из `.info()` - данные имеют пропуск и имеются колонки с типом `object`, что означает наличие строковых (а то и еще каких) данных. Давайте разберемся, как нам сделать базовую предобработку, чтобы построить первую модель!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uQKsstFB55lv"
   },
   "source": [
    "# Базовый анализ данных\n",
    "\n",
    "В этой части мы пройдемся по дополнительным методам подготовки данных для построения базовой модели (к тем, что мы изучили ранее). Целью базового анализа является первое знакомство с данными и подготовка к формату, который позволяет модели работать с данными - численная 2D матрица."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8XjFWC1r6O7S"
   },
   "source": [
    "## Анализ признаков\n",
    "\n",
    "При работе с данными первым делом необходимо понять, что значит каждый признак, какие в нем есть значения и пригодится ли он в работе. Для начала самыми подозрительными признаками являются признаки со строчными или целочисленными значениями, которые имеют слишком много уникальных значений. Как правило к категориальным такое отнести уже сложно, поэтому такие признаки чаще всего исключаются. Для примера возьмем признак `PassengerId`. С виду это какой-то индетификацтор, но взглянем на количество уникальных знчений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "executionInfo": {
     "elapsed": 2357,
     "status": "ok",
     "timestamp": 1601746084104,
     "user": {
      "displayName": "Алексей Девяткин",
      "photoUrl": "",
      "userId": "11945040185410340858"
     },
     "user_tz": -180
    },
    "id": "hJgHLaYs7ts3",
    "outputId": "0f6e431b-84f8-4492-ed10-8e2c648d56c2"
   },
   "outputs": [],
   "source": [
    "print(src_df['PassengerId'].nunique())\n",
    "print(src_df['PassengerId'].count())\n",
    "src_df['PassengerId'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ycdaiwbv71B5"
   },
   "source": [
    "Как видно, абсолютно все значения уникальны, что означает невозможность применения данного признака в работе и он должен быть исключен. Аналогично имеет смысл проверить остальные признаки. Вещественные значения признаков часто также имеют очень много уникальных значений, но их либо сразу относят к типу признаков **непрерывные (численные)**, либо проводят более глубокий анализ.\n",
    "\n",
    "Полезной практикой является проводить в начале унивариативный анализ, показывающий характеристики каждого признака и что с ним можно/нужно сделать в качестве первого этапа базового анализа.\n",
    "\n",
    "Для колонок с типом `object` полезно воспользоваться методом `Series.describe()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "executionInfo": {
     "elapsed": 2331,
     "status": "ok",
     "timestamp": 1601746084104,
     "user": {
      "displayName": "Алексей Девяткин",
      "photoUrl": "",
      "userId": "11945040185410340858"
     },
     "user_tz": -180
    },
    "id": "Q6Igi5pL8j0s",
    "outputId": "f49450f2-5518-476e-923f-c281bb1cd763"
   },
   "outputs": [],
   "source": [
    "src_df['Name'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vk6ow1TG9Mdk"
   },
   "source": [
    "**Вывод:** самым первым этапом базового анализа является анализ признаков, который проводится по каждому признаку с целью определить применимость, необходимость коррекции и другие особенности и проблемы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjprXtZr-iEF"
   },
   "source": [
    "## Заполнение пропусков\n",
    "\n",
    "Для просмотра количества пропусков удобно воспользоаться проверкой на `null` и затем вывести сумму по колонкам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "executionInfo": {
     "elapsed": 2304,
     "status": "ok",
     "timestamp": 1601746084105,
     "user": {
      "displayName": "Алексей Девяткин",
      "photoUrl": "",
      "userId": "11945040185410340858"
     },
     "user_tz": -180
    },
    "id": "a7W5B1CP-taD",
    "outputId": "e4426b99-2292-4a3b-8a0a-c0f7f00d5464"
   },
   "outputs": [],
   "source": [
    "src_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1ZXJNOo-vs6"
   },
   "source": [
    "По результатам отображения количества пропусков видно, что данные имеют пропуски и требуется произвести их обработку, так как данные в таком виде не могут быть применены для построения модели.\n",
    "\n",
    "Существует огромное количество возможных вариантов работы с пропусками (https://scikit-learn.org/stable/modules/impute.html):\n",
    "- Исключение признаков (колонок), имеющих пропуски;\n",
    "- Исключение записей (строк), имеющих пропуски;\n",
    "- Заполнение пропусков средним/медианным значением признака (**Унивариативное** заполнение - Используется единственный признак);\n",
    "- Заполнение пропусков наиболее частым значением признака (мода);\n",
    "- Заполнение путем построения регрессионной модели по остальным признакам (**Мультивариативное** заполнение - используется несколько признаков);\n",
    "- и т.д.\n",
    "\n",
    "Так, например, признак `Age` имеет 177 пропущенных значений, что является достаточно большим количеством, чтобы исключить записи с пропусками. Признак также невозможно исключить, так как он имеет информативный характер (возраст часто связывают со способностью к выживанию). Таким образом, можно воспользоваться `sklearn.impute.SimpleImputer` со стратегией заполнения `mean`, чтобы заполнить пропущенные данные на основе статистики остальных данных данного признака."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "executionInfo": {
     "elapsed": 2278,
     "status": "ok",
     "timestamp": 1601746084105,
     "user": {
      "displayName": "Алексей Девяткин",
      "photoUrl": "",
      "userId": "11945040185410340858"
     },
     "user_tz": -180
    },
    "id": "xGfBcMsx-zJT",
    "outputId": "c5e19977-1e0a-4b43-8427-7e3cce0ca338"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imp = SimpleImputer(strategy='mean')\n",
    "# Двойные скобки использованы, чтобы передать в fit() 2D массив\n",
    "X_in = src_df[['Age']]\n",
    "print(X_in.shape)\n",
    "\n",
    "src_df['Age'] = imp.fit_transform(X_in)\n",
    "src_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-WAgzKBg_H4m"
   },
   "source": [
    "Вот так мы убедились в том, что метод работает! Исходя из распределения данных лучше выбирать стратегию по следующему признаку:\n",
    "- Гауссово распределение - стратегия `mean`, так как в нормальном расрпделении наиболее частое ~ среднее значение;\n",
    "- Ненормальное распределение - стратегия `meadian`, чтобы получить близкое к наиболее частому значению.\n",
    "\n",
    "Для категориальных признаков наиболее простым методом является стратегия `most_frequent`, когда берется наиболее частое значение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "executionInfo": {
     "elapsed": 2251,
     "status": "ok",
     "timestamp": 1601746084106,
     "user": {
      "displayName": "Алексей Девяткин",
      "photoUrl": "",
      "userId": "11945040185410340858"
     },
     "user_tz": -180
    },
    "id": "JLLcdhD5_39x",
    "outputId": "fbbb76b5-3a22-4a26-df1a-9d23f5a39307"
   },
   "outputs": [],
   "source": [
    "imp = SimpleImputer(strategy='most_frequent')\n",
    "src_df['Embarked'] = imp.fit_transform(src_df[['Embarked']])\n",
    "\n",
    "src_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HIFB5fZ6AUd5"
   },
   "source": [
    "Другим методом работы с пропусками является исключение признаков из-за слишком большого количества пропусков:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 2226,
     "status": "ok",
     "timestamp": 1601746084106,
     "user": {
      "displayName": "Алексей Девяткин",
      "photoUrl": "",
      "userId": "11945040185410340858"
     },
     "user_tz": -180
    },
    "id": "SMiDKCY3AgbP",
    "outputId": "1fc2830a-b345-466a-b3ce-566780fa7ec3"
   },
   "outputs": [],
   "source": [
    "src_df['Cabin'].isnull().sum()/src_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12iTKgdSAm46"
   },
   "source": [
    "77% - это слишком большое количество пропусков, чтобы пытаться заполнить!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I-zkmSBY_9LP"
   },
   "source": [
    "## Кодирование признаков\n",
    "\n",
    "Как уже ранее обсуждалось, признаки бывают разные:\n",
    "- Непрерывные (численные) - вещественные или целочисленные (чаще всего представляются типом `float` и `int`);\n",
    "- Категориальные - могут быть представлены строками или числами с небольшим количеством уникальных значений, они могут быть разделены на следующие подтипы:\n",
    "    - Номинальные - значения признаков ограничены группой возможных значений (красный/синий/зеленый);\n",
    "    - Бинарные - те же номинальные, но всего две группы (Да/Нет, Правда/Ложь);\n",
    "    - Последовательные - те же номинальные, но еще группы имеют порядок (плохой/хороший/отличный).\n",
    "\n",
    "Непрерывные признаки с точки зрения базового анализа не требуют особой предобработки, так как они уже представлены числами. Можно лишь попробовать провести их стандартизацию.\n",
    "\n",
    "С категориальными часто бывает чуть сложнее. Наибольшую проблему составляют признаки, которые представлены строками, например признак `Embarked`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416
    },
    "executionInfo": {
     "elapsed": 2202,
     "status": "ok",
     "timestamp": 1601746084107,
     "user": {
      "displayName": "Алексей Девяткин",
      "photoUrl": "",
      "userId": "11945040185410340858"
     },
     "user_tz": -180
    },
    "id": "wnG3Qx8wACV7",
    "outputId": "791765d4-8782-4fa7-d20e-2fa33ffcc9b1"
   },
   "outputs": [],
   "source": [
    "src_df.info()\n",
    "src_df['Embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6yd5SqQHAHAm"
   },
   "source": [
    "Этот признак представлен в данных типом `object` - строка, при этом мы видим, что уникальных значений мало, а это наводит на мысль, что признак - категориальный. Теперь важно понять, имеют ли значения порядок или они независимы? В данном случае логично предположить, что независимы, поэтому присваиваем тип - категориальные номинальный.\n",
    "\n",
    "Но мало просто присвоить тип, нам же нужно подготовить данные для модели, а значит как-то представить в численном виде эти строки.\n",
    "\n",
    "Для этого нам может помочь кодирование One-Hot! Давайте посмотрим, как это делается в `sklearn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "executionInfo": {
     "elapsed": 2437,
     "status": "ok",
     "timestamp": 1601746084367,
     "user": {
      "displayName": "Алексей Девяткин",
      "photoUrl": "",
      "userId": "11945040185410340858"
     },
     "user_tz": -180
    },
    "id": "ZdJGQqDdAIMp",
    "outputId": "3d0d198c-2406-4f7f-dffa-8e4641c2c6d1"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Мы отключим создание разреженного представления, но оно оптимальнее для хранения\n",
    "# Поэтому для отладки лучше использовать и проверять dense представление,\n",
    "#   а для работы в конечном представлении - sparse\n",
    "oh_enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Любой энкодер ненавидит пропуски в данных, поэтому перед использованием\n",
    "#   заполните пропуски в данных\n",
    "X_sample = src_df[['Embarked']]\n",
    "print(X_sample.shape)\n",
    "\n",
    "oh_enc.fit(X_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 2410,
     "status": "ok",
     "timestamp": 1601746084368,
     "user": {
      "displayName": "Алексей Девяткин",
      "photoUrl": "",
      "userId": "11945040185410340858"
     },
     "user_tz": -180
    },
    "id": "4kmcAb54A2O_",
    "outputId": "e24ba42a-950e-4605-f873-1ce0a8b77316"
   },
   "outputs": [],
   "source": [
    "# Можно проверить, какие есть категории\n",
    "oh_enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "executionInfo": {
     "elapsed": 2382,
     "status": "ok",
     "timestamp": 1601746084369,
     "user": {
      "displayName": "Алексей Девяткин",
      "photoUrl": "",
      "userId": "11945040185410340858"
     },
     "user_tz": -180
    },
    "id": "HHSDyg-UA8-8",
    "outputId": "4aa341ee-bc9b-41f6-fa64-7e975af4c84b"
   },
   "outputs": [],
   "source": [
    "# Также посмотреть, что происходит после кодирования с данными\n",
    "X_sample_ohe = oh_enc.transform(X_sample)\n",
    "\n",
    "print(X_sample[:6])\n",
    "print(X_sample_ohe[:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_14IW5_PA9zj"
   },
   "source": [
    "> Теперь попробуйте поменять флаг `sparse` на `True` и посмотреть на результат кодирования. *Dense* (плотное) представление матрицы - это то, к чему мы привыкли, но есть и более экономное - *sparse* (разреженное). В этом случае матрица представлена в виде списка пар (или `dict`), в котором первым элементом (или ключем) обозначается положение в матрице, а вторым - значение. В случае с OHE кодированием sparse представление - дело обычное!\n",
    "\n",
    "\n",
    "Еще одним важным аргументом является поведение энкодера при поступлении новых данных, которые он раньше не видел. Тут многое зависит от задачи, но можно сделать так, чтобы он выдавал ошибку или игнорировал новую категорию, которая не была в обучающих данных:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 2353,
     "status": "ok",
     "timestamp": 1601746084370,
     "user": {
      "displayName": "Алексей Девяткин",
      "photoUrl": "",
      "userId": "11945040185410340858"
     },
     "user_tz": -180
    },
    "id": "bNt2sNLdDdbT",
    "outputId": "b07d476b-cfe7-4eba-a597-dfacda7df491"
   },
   "outputs": [],
   "source": [
    "# Кидаем исключение, если появилась ранее невиданная категория\n",
    "oh_enc = OneHotEncoder(sparse=False, handle_unknown='error')\n",
    "oh_enc.fit(src_df[['Embarked']])\n",
    "\n",
    "# Воспользуемся try-except, чтобы поймать ошибку\n",
    "try:\n",
    "    print(oh_enc.transform(np.array([['K']])))\n",
    "except Exception as e:\n",
    "    print(f'Error happened: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 2328,
     "status": "ok",
     "timestamp": 1601746084371,
     "user": {
      "displayName": "Алексей Девяткин",
      "photoUrl": "",
      "userId": "11945040185410340858"
     },
     "user_tz": -180
    },
    "id": "YUduZqy9ESwZ",
    "outputId": "1a10dba0-3a5c-44ac-f2ef-726ab2f33296"
   },
   "outputs": [],
   "source": [
    "# Или просто игнорируем\n",
    "oh_enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "oh_enc.fit(src_df[['Embarked']])\n",
    "\n",
    "# Воспользуемся try-except, чтобы поймать ошибку\n",
    "try:\n",
    "    print(oh_enc.transform(np.array([['K']])))\n",
    "except Exception as e:\n",
    "    print(f'Error happened: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-g7wBFZBEXEP"
   },
   "source": [
    "1. Первый способ (ошибка) - удобен для проверки, что данные соответсвуют формату и все происходит так как надо - жесткая логика. \n",
    "2. Второй вариант (игнорировать) - более мягкая, но тут надо учитывать, что при обучении модель должна уметь обрабатывать ранее невиданные данные. Такой способ удобен, когда мы сами задаем список категорий:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "executionInfo": {
     "elapsed": 2303,
     "status": "ok",
     "timestamp": 1601746084372,
     "user": {
      "displayName": "Алексей Девяткин",
      "photoUrl": "",
      "userId": "11945040185410340858"
     },
     "user_tz": -180
    },
    "id": "ShF2xo05E40B",
    "outputId": "1b67b27a-7b73-472d-9061-0d2fb0564488"
   },
   "outputs": [],
   "source": [
    "# Или просто игнорируем\n",
    "oh_enc = OneHotEncoder(sparse=False, handle_unknown='ignore', categories=[['C', 'Q']])\n",
    "X_sample = src_df[['Embarked']]\n",
    "oh_enc.fit(X_sample)\n",
    "\n",
    "X_sample_ohe = oh_enc.transform(X_sample)\n",
    "\n",
    "print(X_sample[:6])\n",
    "print(X_sample_ohe[:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lf_KRGRCCrAX"
   },
   "source": [
    "# Полноценная предобработка\n",
    "\n",
    "Когда мы разобрались с тем, как нужно обработать признаки, мы можем поступить двумя способами:\n",
    "- Написать свой код предобработки, протестировать, сохранить категории при кодировании, параметры стандартизации и другие этапы;\n",
    "- Воспользоваться готовыми инструментами, которые делают все действия и на этапе `.fit()` вычисляют и запоминают параметры, чтобы далее во время `.transform()` их применять!\n",
    "\n",
    "Первый способ подходит, когда нет готового инструмента, но `sklearn` имеет огромный арсенал по предобработке, а также можно посмотреть другие фреймворки!\n",
    "\n",
    "Мы пойдем вторым способом и познакомимся с двумя полезными инструментами: [`Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) и [`ColumnTransformer`](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html).\n",
    "\n",
    "Пайплайн позволяет собирать несколько этапов обработки/моделей воедино, чтобы затем пользоваться им как единым целым! Для примера наша обработка категориальных признаков может состоять из двух этапов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iN86MMBfGNLN"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "categorical_features = ['Sex', 'Embarked']\n",
    "\n",
    "# Создаем обработчик категориальный признаков\n",
    "# Так как имеются пропущенные данные в Embarked - \n",
    "#   создадим Pipeline для выполнения нескольких шагов\n",
    "categorical_transformer = Pipeline(\n",
    "    # Шаги в Pipeline указываются как кортежи, каждый из которых\n",
    "    #   представляет собой (имя шага, трансформер)\n",
    "    steps=[\n",
    "        ('imp', SimpleImputer(strategy='most_frequent')),\n",
    "        # Опять sparse для отладки = False\n",
    "        ('enc', OneHotEncoder(sparse=False, handle_unknown='error')),                   \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1gZFo3AdGdw4"
   },
   "source": [
    "Далее, мы снова загрузим данные, чтобы восстановить те проблемы, которые решались до этого и воспользуемся реализацией пайплайна:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "executionInfo": {
     "elapsed": 2231,
     "status": "ok",
     "timestamp": 1601746084374,
     "user": {
      "displayName": "Алексей Девяткин",
      "photoUrl": "",
      "userId": "11945040185410340858"
     },
     "user_tz": -180
    },
    "id": "LssphTHEGmpF",
    "outputId": "abf3452b-de29-4404-9657-0b8328682199"
   },
   "outputs": [],
   "source": [
    "URL = 'https://raw.githubusercontent.com/KaiL4eK/ml_edu/master/datasets/Titanic_train.csv'\n",
    "df = pd.read_csv(URL)\n",
    "\n",
    "categorical_transformer.fit(df[categorical_features])\n",
    "\n",
    "X_transformed = categorical_transformer.transform(df[categorical_features])\n",
    "print(df[categorical_features][:3])\n",
    "print(X_transformed[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 2201,
     "status": "ok",
     "timestamp": 1601746084374,
     "user": {
      "displayName": "Алексей Девяткин",
      "photoUrl": "",
      "userId": "11945040185410340858"
     },
     "user_tz": -180
    },
    "id": "ExESS5S1GvqN",
    "outputId": "946be45d-a53b-4b91-dd88-ae8e7d6d9028"
   },
   "outputs": [],
   "source": [
    "# До конкретных шагов можно добраться через атрибут named_steps\n",
    "categorical_transformer.named_steps['enc'].categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 2175,
     "status": "ok",
     "timestamp": 1601746084375,
     "user": {
      "displayName": "Алексей Девяткин",
      "photoUrl": "",
      "userId": "11945040185410340858"
     },
     "user_tz": -180
    },
    "id": "YdNzdRBWHE4N",
    "outputId": "8d998476-dda7-48ce-b085-7f7240890891"
   },
   "outputs": [],
   "source": [
    "# Или посмотреть названия признаков после кодирования\n",
    "categorical_transformer.named_steps['enc'].get_feature_names(categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U39FbWL4HKyo"
   },
   "source": [
    "> Если обратить внимание, то можно заметить, что `OneHotEncoder` генерирует признаки по количеству категорий, хотя признак `Sex` можно закодировать 0 или 1. Для этого есть аргумент в конструкторе `drop`, который управляет исключением лишних данных. Если его применить, то признак `Sex` в закодированном виде будет представлен всего одной колонкой, что выглядет логичнее.\n",
    "\n",
    "Пайплайн очень удобен тем, что это полноценный объект настраиваемой предобработки, который можно один раз собрать и далее активно пользоваться! Более того, его можно сохранить в файл (сериализация) и затем переносить с сохраненными параметрами!\n",
    "\n",
    "Также, пайплайн позволяет добраться до своих этапов, чтобы получить необходимые атрибуты!\n",
    "\n",
    "Теперь перейдем к другому классу - преобразователь колонок! Его применение в том, чтобы также собирать шаги обработки, но уже указывая, на какие колонки, какая обработка. То есть в пайплайн мы явно передавали данные. `ColumnTransformer` позволяет настроить всю линию предобработки, указывая, какую колонку, чем обрабатывать:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 2144,
     "status": "ok",
     "timestamp": 1601746084376,
     "user": {
      "displayName": "Алексей Девяткин",
      "photoUrl": "",
      "userId": "11945040185410340858"
     },
     "user_tz": -180
    },
    "id": "8JquUK-TH99f",
    "outputId": "13543a69-55f8-424f-8e8c-748bdd36ce98"
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Составляет список признаков для обработки\n",
    "categorical_features = ['Sex', 'Embarked']\n",
    "numeric_features = ['Age', 'Fare']\n",
    "\n",
    "# Создаем обработчик категориальных признаков\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('imp', SimpleImputer(strategy='most_frequent')),\n",
    "        ('enc', OneHotEncoder(handle_unknown='error')),                   \n",
    "])\n",
    "\n",
    "# Численные значения имеют пропуски, заполним стратегией медианы\n",
    "numeric_transformer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Создаем конечный конвертер, который будет использован для \n",
    "#   предобработки\n",
    "preprocessor = ColumnTransformer(\n",
    "    # Список конвертеров, каждый кортеж содержит\n",
    "    #   имя, конвертер и признаки, на которые он будет применен\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "        ('num', numeric_transformer, numeric_features)\n",
    "    ],\n",
    "    # Признаки, не указанные ни в одном из конвертеров будут удалены\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "preprocessor.fit(df)\n",
    "\n",
    "X_data = preprocessor.transform(df)\n",
    "print(type(X_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3_9B1OvHB9Q"
   },
   "source": [
    "На выходе конвертера получается числовая матрица numpy, которую можно уже передавать на вход модели. При этом трансформер колонок позволяет также получать доступ до своих составляющих через атрибут `named_transformers_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 2113,
     "status": "ok",
     "timestamp": 1601746084377,
     "user": {
      "displayName": "Алексей Девяткин",
      "photoUrl": "",
      "userId": "11945040185410340858"
     },
     "user_tz": -180
    },
    "id": "XcrfnxtSJR1O",
    "outputId": "ffa56ae0-ce00-41c8-aecd-2df7daaaafa5"
   },
   "outputs": [],
   "source": [
    "# Получим объект пайплайна категориальных признаков\n",
    "pipe = preprocessor.named_transformers_['cat']\n",
    "# Отобразим категории OHE для шага кодирования\n",
    "print(pipe.named_steps['enc'].categories_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hbe7k4B2J-Vo"
   },
   "source": [
    "При желании можно восстановить представление DataFrame, если из всех шагов собрать имена столбцов результирующей матрицы, но это нужно в редких случаях. А мы всё-таки сделаем для примера:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "executionInfo": {
     "elapsed": 2090,
     "status": "ok",
     "timestamp": 1601746084377,
     "user": {
      "displayName": "Алексей Девяткин",
      "photoUrl": "",
      "userId": "11945040185410340858"
     },
     "user_tz": -180
    },
    "id": "EltBOZl0OLp7",
    "outputId": "3a81ce3a-7b8f-4857-8d5b-a1cf221cfcee"
   },
   "outputs": [],
   "source": [
    "# Для того, чтобы получить имена признаков, воспользуемся функцией\n",
    "#   OneHotEncoder.get_feature_names()\n",
    "# Чтобы ею воспользоваться, необходимо добраться до объекта через атрибуты\n",
    "#   - ColumnTransformer.named_transformers_ + ключ имени\n",
    "#   - Pipeline.named_steps + ключ шага\n",
    "ohe_column_names = preprocessor \\\n",
    "    .named_transformers_['cat'] \\\n",
    "    .named_steps['enc'] \\\n",
    "    .get_feature_names(categorical_features)\n",
    "\n",
    "recovered_feat_names = \\\n",
    "    list(ohe_column_names) + \\\n",
    "    list(numeric_features)\n",
    "\n",
    "df_enc = pd.DataFrame(X_data, columns=recovered_feat_names)\n",
    "\n",
    "df_enc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "executionInfo": {
     "elapsed": 2068,
     "status": "ok",
     "timestamp": 1601746084378,
     "user": {
      "displayName": "Алексей Девяткин",
      "photoUrl": "",
      "userId": "11945040185410340858"
     },
     "user_tz": -180
    },
    "id": "NWO9io8VOUoW",
    "outputId": "3c5277c0-b8f0-445c-caff-f7f76e84773f"
   },
   "outputs": [],
   "source": [
    "# Для сравнения выведем исходные данные\n",
    "df[categorical_features + numeric_features].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wl-Ddd89OL-b"
   },
   "source": [
    "\n",
    "Сутью данного инструмента является сбор инструментов обработки в единый объект уже после этапа поиска подходящих инструментов!\n",
    "\n",
    "Аналогично, нынешний объект `preprocessor` можно разместить внутрь пайплайна вместе с моделью предсказания!\n",
    "![Ну монитор](https://cs8.pikabu.ru/images/big_size_comm/2017-06_6/149883834117099533.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-3jlaUKEbUz"
   },
   "source": [
    "# Разработка модели случайного леса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v2BKnEhyEe-Q"
   },
   "source": [
    "Подход с использование случайного леса (RandomForest) является одним из подходов группы под названием **ансамблирование**.\n",
    "\n",
    "Ансамблирование - это парадигма, при которой большое количество слабых моделей собираются в группу и принятие конечного решения делается на основе голосования этих моделей. Основной девиз - много слабых моделей дают лучший результат, чем одна большая.\n",
    "\n",
    "Подход RandomForest организует набор *решающих деревьев*. Решающее дерево - бинарное дерево, в котором узлами являются пороги одного из обученных признаков, листьями - предсказываемые классы.\n",
    "\n",
    "Для примера обучим решающее дерево для задачи XOR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3086,
     "status": "ok",
     "timestamp": 1601746085417,
     "user": {
      "displayName": "Алексей Девяткин",
      "photoUrl": "",
      "userId": "11945040185410340858"
     },
     "user_tz": -180
    },
    "id": "1lizKt-FGA2J",
    "outputId": "ef28acf7-a58d-4b62-ec4e-6c0dedc127a2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Пример решающего дерева на основе задачи XOR\n",
    "X = np.array([\n",
    "     [1, 1],\n",
    "     [1, 0],\n",
    "     [0, 1],\n",
    "     [0, 0]\n",
    "])\n",
    "\n",
    "y = np.array([\n",
    "     0,\n",
    "     1,\n",
    "     1,\n",
    "     0\n",
    "])\n",
    "\n",
    "plt.figure(figsize=[5,5])\n",
    "plt.scatter(X[y==1, 0], X[y==1, 1], marker='o')\n",
    "plt.scatter(X[y==0, 0], X[y==0, 1], marker='x')\n",
    "plt.xlabel('X[0]')\n",
    "plt.ylabel('X[1]')\n",
    "plt.xlim([-0.5, 1.5])\n",
    "plt.grid()\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "tree.fit(X, y)\n",
    "\n",
    "plt.figure()\n",
    "plot_tree(tree, filled=True, rounded=True, impurity=True, class_names=['0', '1'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Vbk1g4YIzmP"
   },
   "source": [
    "На рисунке представлена визуализация обученного дерева решения для нелинейной задачи XOR. Как видно, каждый узел определяет порог признака, так решение сходится до листьев, в котором и определяется конечное решение дерева (предсказанный класс)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IRMl2ZIBJ3cO"
   },
   "source": [
    "Случайный лес работает по принципу набора таких деревьев:\n",
    "\n",
    "![Замещающий текст](https://miro.medium.com/max/500/1*VHDtVaDPNepRglIAv72BFg.jpeg)\n",
    "\n",
    "Обучение деревьев происходит на основе алгоритма построения дерева (один из них - [CART](http://pages.stat.wisc.edu/~loh/treeprogs/guide/wires11.pdf)  ~ Classification and regression trees). Построение происходит по принципу поиска наилучших разделений пространства на основе одного из признаков для создания узла и дальнейшего роста.\n",
    "\n",
    "Одной из важных особенностей случайного леса является то, что для обучения каждое дерево из леса получает не полную выборку, а лишь подвыборку из всей обучающей выборки. Такой принцип назван **Bagging**.\n",
    "\n",
    "Деревья сами по себе очень чувствительны ко входным данным, так как могут бесконечно создавать узлы по признакам, чтобы максимально точно разделить классы. По факту, дерево очень легко переобучается на тех данных, которые даны для обучения (построения), если не ограничить глубину дерева.\n",
    "\n",
    "Поэтому при построении каждого малого дерева используется подвыборка, куда могут попадать с повторениями случайные записи из данных со случайными признаками. Таким образом, каждая модель будет видеть лишь часть данных, при этом отдельно каждая слабая модель будет работать плохо, но в совокупности все модели будут давать более точную среднюю оценку в соответсвии с принятием решения по большинству голосов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 3065,
     "status": "ok",
     "timestamp": 1601746085419,
     "user": {
      "displayName": "Алексей Девяткин",
      "photoUrl": "",
      "userId": "11945040185410340858"
     },
     "user_tz": -180
    },
    "id": "QwZTs7_E4mxs",
    "outputId": "308c3974-e5f5-4222-af80-362d3124b51e"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TRAIN_RATIO = 0.8\n",
    "\n",
    "y_data = df['Survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_data, y_data, \n",
    "    train_size=TRAIN_RATIO, \n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y_data\n",
    ")\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "executionInfo": {
     "elapsed": 3693,
     "status": "ok",
     "timestamp": 1601746086068,
     "user": {
      "displayName": "Алексей Девяткин",
      "photoUrl": "",
      "userId": "11945040185410340858"
     },
     "user_tz": -180
    },
    "id": "KXN4pILYp-fR",
    "outputId": "d537e18e-df5e-41b3-af1b-4274e767f9c4"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzunrMbXoN7Y"
   },
   "source": [
    "# Важность признаков\n",
    "\n",
    "Обучение модели случайного леса позволяет получить оценку важности признаков! Для работы с показателями важности признаков достаточно воспользоваться атрибутом `RandomForestClassifier.feature_importances_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 812
    },
    "executionInfo": {
     "elapsed": 3670,
     "status": "ok",
     "timestamp": 1601746086070,
     "user": {
      "displayName": "Алексей Девяткин",
      "photoUrl": "",
      "userId": "11945040185410340858"
     },
     "user_tz": -180
    },
    "id": "s7Dxqam-qRoX",
    "outputId": "713e3415-bf79-476d-bd58-413a09a435db"
   },
   "outputs": [],
   "source": [
    "def show_importance(model, feature_names, X):\n",
    "    importances = model.feature_importances_\n",
    "    for feat_imp, feat_name in zip(importances, feature_names):\n",
    "        print(f'Feature: {feat_name} | {feat_imp}')\n",
    "\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    sorted_feat_names = [feature_names[ind] for ind in indices]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.bar(range(X.shape[1]), importances[indices], color=\"b\", align=\"center\")\n",
    "    plt.xticks(range(X.shape[1]), sorted_feat_names, rotation=70)\n",
    "    plt.xlim([-1, X.shape[1]])\n",
    "    plt.show()\n",
    "\n",
    "show_importance(rf_clf, recovered_feat_names, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0TqmtpDirZG4"
   },
   "source": [
    "Такой график показывает, как признаки влияли на построение деревьев и насколько каждый из них важен по отношению к другим. \n",
    "\n",
    "> **ВАЖНО:** Несмотря на то, что цель графика - показать, насколько важны признаки для предсказания, **нельзя** полагаться лишь на результаты анализа лесом! Часто такая оценка важности смещена. Для более полного анализа в заданиях попробуйте воспользоваться подходом под названием *Feature Elimination*, который более точно позволяет оценить, какие признаки имеют высокое влияние на принимаемое решение модели! Суть подхода в том, что мы постепенно удаляем один за другим признаки из данных и оцениваем, как это повлияло на работу модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6JRKX9SPI55"
   },
   "source": [
    "# Расширенный анализ данных\n",
    "\n",
    "Результаты построения baseline модели как правило позволяют оценить результаты, которые можно получить наиболее быстрым способом. Дальнейших улучшений можно добиться как настраиванием модели и усложнением алгоритма, так и поиском \"инсайтов\" в данных, что позволит модели более просто понимать зависимости и принимать правильные решения. Для расширения знаний и подходов предлагаю ознакомиться с [хорошей статьей по EDA](https://towardsdatascience.com/predicting-the-survival-of-titanic-passengers-30870ccc7e8), а мы рассмотрим несколько основных способов проанализировать данные и сделать выводы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g3rwugsCQntR"
   },
   "source": [
    "### Больше графиков!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KHC3u0UgP1d9"
   },
   "source": [
    "Один из самых простых способов проверить пользу признака - анализ нескольких признаков в совокупности, чтобы понять, какие взаимосвязи имеются и дает ли признак информацию. Начнем с того, что постараемся определить, кто чаще выживает - мужчины или женщины:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "executionInfo": {
     "elapsed": 3650,
     "status": "ok",
     "timestamp": 1601746086071,
     "user": {
      "displayName": "Алексей Девяткин",
      "photoUrl": "",
      "userId": "11945040185410340858"
     },
     "user_tz": -180
    },
    "id": "JOqClg-dQMyT",
    "outputId": "c7583dda-21ce-4a8a-bd43-94b62c54f84c"
   },
   "outputs": [],
   "source": [
    "sns.catplot(x=\"Sex\", hue=\"Survived\", kind=\"count\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vB9lnFfTQPAV"
   },
   "source": [
    "Ответ на графике - выживаемость (Survived = 1) у женского пола больше, что означает необходимость использвания данного признака, так как он влияет на конечное решение! Если бы графики были ровные (все на одном уровне), мы бы не могли по полу человека сказать, кто скорее всего выживет, а значит такой признак бесполезен!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VK7V7MUHTjyN"
   },
   "source": [
    "Еще одним интересный признак `Pclass`, класс обслуживания, можно проверить, влияет ли он на выживаемость:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 632
    },
    "executionInfo": {
     "elapsed": 3868,
     "status": "ok",
     "timestamp": 1601746086312,
     "user": {
      "displayName": "Алексей Девяткин",
      "photoUrl": "",
      "userId": "11945040185410340858"
     },
     "user_tz": -180
    },
    "id": "Pq7J7MptTt0N",
    "outputId": "768a1a8f-c8a4-4a98-cb82-c9c994a5d1f3"
   },
   "outputs": [],
   "source": [
    "sns.barplot(x='Pclass', y='Survived', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CGK8EjIrQp6J"
   },
   "source": [
    "Как видно, класс тоже вносит свое влияние в выживаемость: обслуживание первого класса более склонно к выживанию.\n",
    "\n",
    "Также можно влияние признака проверить отображением через `sns.FacetGrid`, чтобы проверить все значения, связанные с несколькими признаками:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 990
    },
    "executionInfo": {
     "elapsed": 5173,
     "status": "ok",
     "timestamp": 1601746087638,
     "user": {
      "displayName": "Алексей Девяткин",
      "photoUrl": "",
      "userId": "11945040185410340858"
     },
     "user_tz": -180
    },
    "id": "Q2uxeuFNSNFl",
    "outputId": "0fc79a35-6280-4242-826a-7a73c220a383"
   },
   "outputs": [],
   "source": [
    "FacetGrid = sns.FacetGrid(df, row='Embarked', height=4.5, aspect=1.6)\n",
    "FacetGrid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette=None,  order=None, hue_order=None)\n",
    "FacetGrid.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HiaWOyaHUBQl"
   },
   "source": [
    "Как видно, в зависимости от порта посадки, а одних случаях (порты Q и S) женский пол имеет большие шансы на выживание, чего не скажешь о порте C. Тоже свой вклад в предсказания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1QBBWh_qUX27"
   },
   "source": [
    "## Создание новых признаков\n",
    "\n",
    "Помимо исключения признаков одним из широкоприменяемых подходов является создание новых признаков. Для примера, наличие двух признаков `SibSp` и `Parch` сообщает информацию о количестве родственников на борту. Таким образом, можно сформировать дополнительный признак `FamilySize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BDUAzI3qUc6c"
   },
   "outputs": [],
   "source": [
    "# +1 - we are in family too\n",
    "df['FamilySize'] = df['Parch'] + df['SibSp'] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PPBQjUK6Ueco"
   },
   "source": [
    "Новые признаки являются производными от исходных признаков, при этом зависимости не всегда могут являться линейными (например, из даты получить бинарную информацию, является ли день выходным или нет). Такие признаки могут помочь модели найти новые зависимостии и повысить точность.\n",
    "\n",
    "> Как и ранее с генерацией полиномиальных признаков, можно проводить базовые операции над признаками (унивариативно или над несколькими). С одной стороны, можно делать операции на основе логических допущений - если вы понимаете, что новые признаки точно дадут новую информацию. В другой стороны, можно просто перебирать, пока не найдете такие операции, которые дадут прирост в точности, но это бывает долго и неэффективно.\n",
    "\n",
    "Для примера после того, как мы создали свой признак \"размер семьи\", то можно отобразить единый график шансов выживания:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 614
    },
    "executionInfo": {
     "elapsed": 5494,
     "status": "ok",
     "timestamp": 1601746087992,
     "user": {
      "displayName": "Алексей Девяткин",
      "photoUrl": "",
      "userId": "11945040185410340858"
     },
     "user_tz": -180
    },
    "id": "xosyxIECUq81",
    "outputId": "606c5143-93e0-41f9-af3f-d37fc40ae869"
   },
   "outputs": [],
   "source": [
    "axes = sns.pointplot(x='FamilySize', y='Survived', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NRr6E7SKUg_i"
   },
   "source": [
    "По такому графику можем видеть, что в зависимости от количества членов семьи меняются и шансы на выживание, при этом есть некоторая \"критическая точка\", что в четыре человека выжить больше шансов, нежели дальнейшее увеличение количества людей в семье на борту."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-balBdsVlJ4"
   },
   "source": [
    "## Группировка данных (binning)\n",
    "\n",
    "Одним из способов предобработки данных является группировка численные признаков для формирования категориального признака. Суть подхода в том, чтобы заменить непрерывное значение группами, каждая из которых описывает диапазон значений. Таким образом численное значение заменяется категориальным последовательным.\n",
    "\n",
    "Такой подход является с одной стороны методом регуляризации, так как модель учится не на точных значениях, а на группах значений. С другой стороны, такой подход теряет часть информации.\n",
    "\n",
    "Для примера разберем признак `Fare`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 686
    },
    "executionInfo": {
     "elapsed": 5773,
     "status": "ok",
     "timestamp": 1601746088292,
     "user": {
      "displayName": "Алексей Девяткин",
      "photoUrl": "",
      "userId": "11945040185410340858"
     },
     "user_tz": -180
    },
    "id": "v-u16gMOVo9C",
    "outputId": "39277ab5-ea5f-4242-a67e-6f710f32d3d8"
   },
   "outputs": [],
   "source": [
    "sns.distplot(df['Fare'], bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHhgSZAcVs1g"
   },
   "source": [
    "Раcпределение немного сдвинуто влево, также слева имеется небольшая мода. Для группировки воспользуется классом `KBinsDiscretizer`, который разделяет весь диапазон на заданное количество групп (бинов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 5994,
     "status": "ok",
     "timestamp": 1601746088533,
     "user": {
      "displayName": "Алексей Девяткин",
      "photoUrl": "",
      "userId": "11945040185410340858"
     },
     "user_tz": -180
    },
    "id": "N5GDtNPrVtxA",
    "outputId": "f2393503-1e7c-4ffc-ecc3-0a54e2a3e8c5"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "discr = KBinsDiscretizer(\n",
    "    # Количество бинов    \n",
    "    n_bins=10,\n",
    "    # Способ кодирования - порядковый\n",
    "    encode='ordinal',\n",
    ")\n",
    "\n",
    "# Двойные скобки для передачи DataFrame (2D данные)\n",
    "df['Fare_groups'] = discr.fit_transform(df[['Fare']])\n",
    "# Отобразим границы бинов\n",
    "print(discr.bin_edges_)\n",
    "\n",
    "sns.catplot(x='Fare_groups', kind=\"count\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qetwJxu4VxLc"
   },
   "source": [
    "Группировка, как видно, привела сильно смещенное влево распределение к равномерному.\n",
    "\n",
    "Более того, теперь мы можем визуально представить зависимость выживаемости от стоимости билета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "executionInfo": {
     "elapsed": 6619,
     "status": "ok",
     "timestamp": 1601746089178,
     "user": {
      "displayName": "Алексей Девяткин",
      "photoUrl": "",
      "userId": "11945040185410340858"
     },
     "user_tz": -180
    },
    "id": "1viL6R2rYoV4",
    "outputId": "1b8eef5c-4db9-4f8b-d077-d840c8ac844d"
   },
   "outputs": [],
   "source": [
    "sns.catplot(x='Fare_groups', y='Survived', data=df, kind='point')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_MySO9JhfwYQ"
   },
   "source": [
    "или"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "executionInfo": {
     "elapsed": 7164,
     "status": "ok",
     "timestamp": 1601746089742,
     "user": {
      "displayName": "Алексей Девяткин",
      "photoUrl": "",
      "userId": "11945040185410340858"
     },
     "user_tz": -180
    },
    "id": "-2Xo8N-Dfw99",
    "outputId": "b60daaa7-acb7-46c5-978f-95912f75fa2a"
   },
   "outputs": [],
   "source": [
    "sns.catplot(x='Fare_groups', hue='Survived', data=df, kind='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5H_58I_0ZhPf"
   },
   "source": [
    "Как видим, сгруппированный признак отображает определенную зависимость выживаемости и стоимости билета. Более высокая стоимость билета имеет больший шанс на выживание.\n",
    "\n",
    "При этом обратите внимание, что сейчас деление на группы произведено по стратегии равного количества во всех группах. Можно попробовать сделать деление по равным диапазонам групп и сравнить!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sFvp4-nY0pQS"
   },
   "source": [
    "# Поиск гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PH1FOJ-s0pwP"
   },
   "source": [
    "Как известно, многие модели имеют различные параметры, которые влияют на ход построения модели, максимальные и минимальные ограничения в структуре и др. При этом помним, что и сами модели имеют обучаемые параметры (для случая линейной регрессии, например, это веса при признаках). Те параметры, которые не участвуют в предсказании, но определяют архитектуру или другие внешние характеристики модели называют **гиперпараметрами**.\n",
    "\n",
    "Уже не раз было необходимо произвести поиск и оценку этих гиперпараметров (в KNN - количество соседелей, в Ридж регрессии - $\\alpha$). Ручной поиск хорошо справляется, когда имеется опыт и понимание работы модели, но также существуют и автоматизированные методы поиска - одним из них является **GridSearch**.\n",
    "\n",
    "Основная суть метода в том, что для каждого гиперпараметра задается набор значений, которые требуется попробовать и далее создаётся набор из всех возможных комбинаций заданных гиперпараметров и их значений. Таким образом, исследуемые значения располагаются \"как-бы на сетке\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y0lMOLyP00Yq"
   },
   "source": [
    "В качестве реализации воспользуемся классом `sklearn.model_selection.GridSearchCV`, который реализует GridSearch с кросс-валидацией."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "executionInfo": {
     "elapsed": 10123,
     "status": "ok",
     "timestamp": 1601746092722,
     "user": {
      "displayName": "Алексей Девяткин",
      "photoUrl": "",
      "userId": "11945040185410340858"
     },
     "user_tz": -180
    },
    "id": "n3sSK28h01oz",
    "outputId": "31613239-7fb0-4cea-d8b4-a2ee1e5ed04e"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'max_depth': [1, 2, 4, 5, 7],\n",
    "    'n_estimators': [1, 5, 10, 20, 40],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    # модель\n",
    "    estimator=rf_clf,                   \n",
    "    # сетка параметров\n",
    "    #   может быть объектом dict \n",
    "    #   или list с несколькими dict внутри (несколько сеток)\n",
    "    param_grid=parameters,              \n",
    "    # кол-во фолдов для CV\n",
    "    cv=5,                               \n",
    "    # метрика для оценки - используем F1 \n",
    "    scoring='f1_macro',   \n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "executionInfo": {
     "elapsed": 13129,
     "status": "ok",
     "timestamp": 1601746095744,
     "user": {
      "displayName": "Алексей Девяткин",
      "photoUrl": "",
      "userId": "11945040185410340858"
     },
     "user_tz": -180
    },
    "id": "pBq-4BahUGoc",
    "outputId": "a8d2815b-89a0-4907-f5b3-150e83f509b8"
   },
   "outputs": [],
   "source": [
    "# Для поиска параметров модели внутри пайплайна используется специальное именование:\n",
    "#   <название шага>__<название параметра>\n",
    "pipe = Pipeline(steps=[\n",
    "    ('clf', RandomForestClassifier()),\n",
    "])\n",
    "\n",
    "# В названии два подчеркивания!\n",
    "parameters = {\n",
    "    'clf__max_depth': [1, 2, 4, 5, 7],\n",
    "    'clf__n_estimators': [1, 5, 10, 20, 40],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    # пайплайн\n",
    "    estimator=pipe,                   \n",
    "    param_grid=parameters,              \n",
    "    cv=5,                               \n",
    "    scoring='f1_macro',   \n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dWFNLF105-k"
   },
   "source": [
    "После того, как поиск закончен, можно посмотреть на сетку сгенерированных параметров через аттрибут `cv_results_` и ключ `params`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "executionInfo": {
     "elapsed": 13111,
     "status": "ok",
     "timestamp": 1601746095745,
     "user": {
      "displayName": "Алексей Девяткин",
      "photoUrl": "",
      "userId": "11945040185410340858"
     },
     "user_tz": -180
    },
    "id": "fXP8lsIc0649",
    "outputId": "fd9434e7-e996-40d7-dafd-e4541cb5efc5"
   },
   "outputs": [],
   "source": [
    "grid_search.cv_results_['params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x2yKa2I50-0m"
   },
   "source": [
    "Для получения наилучших параметров и оценки можно воспользоваться аттрибутами `best_params_` и `best_score_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 13086,
     "status": "ok",
     "timestamp": 1601746095746,
     "user": {
      "displayName": "Алексей Девяткин",
      "photoUrl": "",
      "userId": "11945040185410340858"
     },
     "user_tz": -180
    },
    "id": "mzZO93G-0_Eu",
    "outputId": "8ff5dfac-ef73-41cc-82de-5eddd775aab3"
   },
   "outputs": [],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zs3yq1WWgclZ"
   },
   "source": [
    "Аналогично для `ColumnTransformer`, для учета этапов необходимо использовать `__` для каждой агрегации операций (пайплайн или трансформер колонок). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o1jNdLJv8lSc"
   },
   "source": [
    "# Задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-gluX0Ug8p9W"
   },
   "source": [
    "- Проведите базовый анализ данных, разделите данные на обучение/тест, разработайте baseline модель решающего дерева [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html), оцените работу модели, отобразите важности признаков;\n",
    "- Разработайте модель линейной регрессии, оцените и сравните с моделью дерева;\n",
    "- Произведите стандартизацию численных признаков и оцените (сравните) работу моделей с результатами обучения без стандартизации;\n",
    "- Изучите влияние `max_depth` и `criterion` на показатели дерева, попробуйте 5 разных значений для каждого критерия, оцените с помощью кросс-валидации на обучающей выборке, сделайте таблицу;\n",
    "- Проведите расширенный анализ данных, выберите наиболее приоритетные для классификации признаки, сравните выбранные признаки с показателями важности признаков, создайте новые признаки; В результате расширенного анализа обратите внимание на следующие особенностями:\n",
    "    - Проведите создание новых признаков, добавляя каждый новый признак проведите оценку модели:\n",
    "        - `FamilySize` - размер родственников на корабле;\n",
    "        - `IsAlone` - является ли пассажир один на корабле или нет (бинарный признак);\n",
    "        - `FarePerPerson` - оплата билета на человека в семье (воспользоваться `FamilySize`);\n",
    "        - \\*`NameTitle` (если придумаете как) - название титула, сформированое из признака `Name`, редкие титулы стоит объединить в одну группу;\n",
    "    - Оцените работу модели при добавлении группировки признаков `Age`, `Fare`;\n",
    "- Обучите модель дерева и модель леса [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) по подготовленным данным;\n",
    "- Оцените влияние аргументов `max_depth` и `n_estimators` на точность модели (5 значений для каждого) с помощью кросс-валидации на обучающей выборке. Постройте таблицу зависимости метрик от величин;\n",
    "- Определите наилучшие параметры для модели случайного леса через [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html);\n",
    "- Определите наилучшие параметры для модели случайного леса через [RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html);\n",
    "- Постройте лучшие модели леса и решающего дерева и сравните их по показателям на выборке для теста.\n",
    "- Примените подход [Recursive Feature Elimination](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html) на лучшую модель случайного леса. Сравните оценку важности признаков RFE и то, что показывает лес.\n",
    "- Постройте ROC кривые моделей, сравните их и сделайте выводы:\n",
    "    - лучшая модель на всех признаках;\n",
    "    - лучшая модель только на топ-7 лучших признаках по RFE;\n",
    "    - лучшая модель на топ-5 лучших признаках по RFE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APk6mh5eMbBe"
   },
   "source": [
    "# Вопросы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vv8T3Z8QMcFb"
   },
   "source": [
    "- Какой метод оценки модели лучше использовать в данной работе? Разделение на обучение/тест или кросс-валидация? Можно/нужно ли применять их вместе?\n",
    "- За что отвечают параметры `max_depth` и `n_estimators` в модели случайных лесов? Как они влияют на работу модели?\n",
    "- В чем отличие GridSearch от RandomSearch?\n",
    "- Как влияет стандартизация признаков на работу модели леса?\n",
    "- Что такое \"важность признака\"? Есть ли аналоги показателя в моделях линейной и логистической регрессии?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c5RB98mrM6iR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab3_RandomForest.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
